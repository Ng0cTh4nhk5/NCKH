# Stage 2: Automated Credit Scoring Pipeline - Implementation Plan (Modular Architecture)

K·∫ø ho·∫°ch thi·∫øt k·∫ø h·ªá th·ªëng ch·∫•m ƒëi·ªÉm t√≠n d·ª•ng t·ª± ƒë·ªông cho SME v·ªõi **ki·∫øn tr√∫c modular** 4 t·∫ßng, kh·∫£ nƒÉng x·ª≠ l√Ω th·ªùi gian th·ª±c v√† m·ªü r·ªông.

> [!NOTE]
> **Vai tr√≤ t√†i li·ªáu**: ƒê√¢y l√† k·∫ø ho·∫°ch t∆∞ v·∫•n (advisory plan). Ng∆∞·ªùi th·ª±c hi·ªán s·∫Ω t·ª± tri·ªÉn khai d·ª±a tr√™n h∆∞·ªõng d·∫´n n√†y.

> [!IMPORTANT]
> **C·∫≠p nh·∫≠t quan tr·ªçng**: Plan n√†y ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ √°p d·ª•ng **Modular Architecture** v·ªõi 4 scoring modules ƒë·ªôc l·∫≠p, d·ª±a tr√™n th·ª±c ti·ªÖn th·∫©m ƒë·ªãnh t√≠n d·ª•ng DN nh·ªè t·∫°i Vi·ªát Nam. Ki·∫øn tr√∫c n√†y gi√∫p:
> - X·ª≠ l√Ω t·ªët h∆°n khi thi·∫øu d·ªØ li·ªáu
> - D·ªÖ debug v√† maintain
> - TƒÉng kh·∫£ nƒÉng gi·∫£i th√≠ch (explainability)
> - Linh ho·∫°t trong vi·ªác m·ªü r·ªông

## Ph·∫°m vi & R√†ng bu·ªôc H·ªá th·ªëng

### Gi·ªõi h·∫°n ƒê·ªãa l√Ω
- **Khu v·ª±c**: Ch·ªâ √°p d·ª•ng cho **Th√†nh ph·ªë H·ªì Ch√≠ Minh**
- **L√Ω do**: ƒê·ªÅ t√†i nghi√™n c·ª©u t·∫≠p trung v√†o c√°c ng√¢n h√†ng th∆∞∆°ng m·∫°i t·∫°i TP.HCM
- **Impact**: 
  - D·ªØ li·ªáu ƒë·ªãa l√Ω (province_code) s·∫Ω c·ªë ƒë·ªãnh l√† HCMC
  - C√≥ th·ªÉ t·∫≠n d·ª•ng d·ªØ li·ªáu kinh t·∫ø vƒ© m√¥ ƒë·∫∑c th√π c·ªßa TP.HCM
  - Location risk score c√≥ th·ªÉ chi ti·∫øt ƒë·∫øn c·∫•p qu·∫≠n/huy·ªán trong HCM

### Gi·ªõi h·∫°n Ng√†nh ngh·ªÅ
- **Scope hi·ªán t·∫°i**: **Ch∆∞a gi·ªõi h·∫°n ng√†nh ngh·ªÅ c·ª• th·ªÉ**
- **Recommend**: Khi tri·ªÉn khai th·ª±c t·∫ø, n√™n ∆∞u ti√™n c√°c ng√†nh:
  - Th∆∞∆°ng m·∫°i (B√°n l·∫ª, B√°n s·ªâ)
  - S·∫£n xu·∫•t quy m√¥ nh·ªè
  - D·ªãch v·ª• (F&B, Logistics)
  - Xu·∫•t nh·∫≠p kh·∫©u

### Quy m√¥ SME
- Doanh nghi·ªáp v·ª´a v√† nh·ªè theo Ngh·ªã ƒë·ªãnh 39/2018/Nƒê-CP
- Doanh thu: < 200 t·ª∑ VNƒê/nƒÉm
- S·ªë lao ƒë·ªông: < 200 ng∆∞·ªùi

## M·ª•c ti√™u to√°n h·ªçc

### Ki·∫øn tr√∫c Modular 2-t·∫ßng

**T·∫ßng 1: Specialized Scoring Modules**

T√¨m 4 h√†m √°nh x·∫° chuy√™n bi·ªát:

```
S‚ÇÅ = f‚ÇÅ(X_financial)           ‚Üí Financial Health Score [0,1]
S‚ÇÇ = f‚ÇÇ(X_credit)              ‚Üí Credit Behavior Score [0,1]  
S‚ÇÉ = f‚ÇÉ(X_business)            ‚Üí Business Quality Score [0,1]
S‚ÇÑ = f‚ÇÑ(X_stability)           ‚Üí Stability & Risk Score [0,1]
```

**T·∫ßng 2: Meta-Ensemble Model**

T√¨m h√†m k·∫øt h·ª£p t·ªëi ∆∞u:

```
≈∑ = f_meta(S‚ÇÅ, S‚ÇÇ, S‚ÇÉ, S‚ÇÑ)     ‚Üí Probability of Default [0,1]
```

Trong ƒë√≥:
- **≈∑**: X√°c su·∫•t v·ª° n·ª£ (Probability of Default - PD)
- **S‚ÇÅ-S‚ÇÑ**: ƒêi·ªÉm s·ªë trung gian t·ª´ 4 modules chuy√™n bi·ªát
- **X**: C√°c vector ƒë·∫∑c tr∆∞ng ƒë√£ ƒë∆∞·ª£c s·ªë h√≥a, ƒë∆∞·ª£c nh√≥m theo domain

**∆Øu ƒëi·ªÉm ki·∫øn tr√∫c n√†y:**
- ‚úÖ X·ª≠ l√Ω robust khi thi·∫øu d·ªØ li·ªáu (module n√†o thi·∫øu data v·∫´n c√≥ th·ªÉ d√πng default score)
- ‚úÖ Explainable: C√≥ th·ªÉ ph√¢n t√≠ch t·ª´ng kh√≠a c·∫°nh ri√™ng bi·ªát
- ‚úÖ Maintainable: Update/retrain t·ª´ng module ƒë·ªôc l·∫≠p
- ‚úÖ Scalable: D·ªÖ d√†ng th√™m modules m·ªõi (VD: Social Media Score)

---

## 1. Quy tr√¨nh Th·∫©m ƒë·ªãnh T√≠n d·ª•ng Chu·∫©n (Th·ª±c t·∫ø)

### Flowchart Quy tr√¨nh Truy·ªÅn th·ªëng

```mermaid
flowchart TD
    Start([Kh√°ch h√†ng n·ªôp h·ªì s∆° vay]) --> SurveyCheck{Kh·∫£o s√°t<br/>ban ƒë·∫ßu}
    
    SurveyCheck -->|ƒê·∫°t| DocCollect[Thu th·∫≠p h·ªì s∆°]
    SurveyCheck -->|Kh√¥ng ƒë·∫°t| Reject1([T·ª´ ch·ªëi])
    
    DocCollect --> DocVerify{X√°c minh<br/>h·ªì s∆°}
    DocVerify -->|Thi·∫øu/Sai| RequestMore[Y√™u c·∫ßu b·ªï sung]
    RequestMore --> DocCollect
    DocVerify -->|ƒê·∫ßy ƒë·ªß| FinAnalysis[Ph√¢n t√≠ch t√†i ch√≠nh]
    
    FinAnalysis --> RatioCalc[T√≠nh c√°c ch·ªâ s·ªë:<br/>- ROE, ROA<br/>- Current Ratio<br/>- Debt/Equity<br/>- DSCR]
    
    RatioCalc --> CreditHistory[Ki·ªÉm tra l·ªãch s·ª≠<br/>t√≠n d·ª•ng CIC]
    
    CreditHistory --> CollateralCheck[Th·∫©m ƒë·ªãnh<br/>t√†i s·∫£n ƒë·∫£m b·∫£o]
    
    CollateralCheck --> SiteVisit[Kh·∫£o s√°t<br/>th·ª±c ƒë·ªãa]
    
    SiteVisit --> RiskAnalysis[Ph√¢n t√≠ch<br/>r·ªßi ro]
    
    RiskAnalysis --> CreditCommittee{H·ªôi ƒë·ªìng<br/>t√≠n d·ª•ng}
    
    CreditCommittee -->|ƒê·∫°t| Approve[Ph√™ duy·ªát]
    CreditCommittee -->|Kh√¥ng ƒë·∫°t| Reject2([T·ª´ ch·ªëi])
    CreditCommittee -->|C·∫ßn b·ªï sung| RequestMore
    
    Approve --> Disbursement([Gi·∫£i ng√¢n])
    
    style Start fill:#90EE90
    style Disbursement fill:#90EE90
    style Reject1 fill:#FFB6C6
    style Reject2 fill:#FFB6C6
    style CreditCommittee fill:#FFD700
    style RiskAnalysis fill:#FFA500
```

### C√°c ƒëi·ªÉm ra quy·∫øt ƒë·ªãnh ch√≠nh

1. **Kh·∫£o s√°t ban ƒë·∫ßu**: L·ªçc s∆° b·ªô kh√°ch h√†ng kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán
2. **X√°c minh h·ªì s∆°**: Ki·ªÉm tra t√≠nh ƒë·∫ßy ƒë·ªß v√† h·ª£p l·ªá
3. **Ph√¢n t√≠ch ch·ªâ s·ªë t√†i ch√≠nh**: ƒê√°nh gi√° nƒÉng l·ª±c t√†i ch√≠nh
4. **L·ªãch s·ª≠ t√≠n d·ª•ng**: Ki·ªÉm tra CIC, n·ª£ x·∫•u
5. **T√†i s·∫£n ƒë·∫£m b·∫£o**: Th·∫©m ƒë·ªãnh gi√° tr·ªã TSƒêB
6. **H·ªôi ƒë·ªìng t√≠n d·ª•ng**: Quy·∫øt ƒë·ªãnh cu·ªëi c√πng

### Th·ªùi gian x·ª≠ l√Ω truy·ªÅn th·ªëng: **5-15 ng√†y l√†m vi·ªác**

---

## 2. Quy tr√¨nh Th·∫©m ƒë·ªãnh T√≠n d·ª•ng T·ª± ƒë·ªông

### Flowchart Quy tr√¨nh T·ª± ƒë·ªông h√≥a

```mermaid
flowchart TD
    Start([API nh·∫≠n d·ªØ li·ªáu]) --> DataValidation{Validation<br/>d·ªØ li·ªáu ƒë·∫ßu v√†o}
    
    DataValidation -->|Invalid| ErrorResponse([Tr·∫£ l·ªói])
    DataValidation -->|Valid| DataEnrich[Data Enrichment:<br/>- G·ªçi API CIC<br/>- Truy v·∫•n d·ªØ li·ªáu n·ªôi b·ªô<br/>- Thu th·∫≠p d·ªØ li·ªáu thay th·∫ø]
    
    DataEnrich --> FeatureExtraction[Feature Extraction:<br/>Tr√≠ch xu·∫•t 50+ features]
    
    FeatureExtraction --> FeatureEngineering[Feature Engineering:<br/>- T√≠nh to√°n ch·ªâ s·ªë<br/>- Chu·∫©n h√≥a<br/>- X·ª≠ l√Ω missing values]
    
    FeatureEngineering --> ModelPrediction[Model Prediction:<br/>Ensemble c·ªßa:<br/>- XGBoost<br/>- Random Forest<br/>- LightGBM]
    
    ModelPrediction --> PDCalculation[T√≠nh PD Score:<br/>≈∑ = f_ensemble_X]
    
    PDCalculation --> RiskSegmentation{Ph√¢n lo·∫°i<br/>r·ªßi ro}
    
    RiskSegmentation -->|PD < 0.05| AutoApprove[Auto-Approve<br/>Low Risk]
    RiskSegmentation -->|0.05 ‚â§ PD < 0.15| ManualReview[Manual Review<br/>Medium Risk]
    RiskSegmentation -->|PD ‚â• 0.15| AutoReject[Auto-Reject<br/>High Risk]
    
    AutoApprove --> LimitCalc[T√≠nh h·∫°n m·ª©c<br/>& l√£i su·∫•t]
    ManualReview --> HumanExpert[Chuy√™n gia<br/>th·∫©m ƒë·ªãnh]
    
    LimitCalc --> Response([Tr·∫£ k·∫øt qu·∫£])
    HumanExpert --> Response
    AutoReject --> Response
    
    Response --> Monitoring[Real-time Monitoring<br/>& Logging]
    
    style Start fill:#90EE90
    style Response fill:#90EE90
    style ErrorResponse fill:#FFB6C6
    style AutoApprove fill:#98FB98
    style AutoReject fill:#FFB6C6
    style ManualReview fill:#FFD700
    style ModelPrediction fill:#87CEEB
```

### Th·ªùi gian x·ª≠ l√Ω t·ª± ƒë·ªông: **< 5 ph√∫t** (Near Real-time)

---

## 3. Ki·∫øn tr√∫c Modular v√† Ph√¢n b·ªï ƒê·∫∑c tr∆∞ng

### T·ªïng quan Ki·∫øn tr√∫c

H·ªá th·ªëng s·ª≠ d·ª•ng **4 Scoring Modules** chuy√™n bi·ªát, m·ªói module t·∫≠p trung v√†o m·ªôt kh√≠a c·∫°nh c·ªßa credit risk:

```mermaid
graph TB
    subgraph "Input Layer"
        I1[Raw Data t·ª´ c√°c ngu·ªìn]
    end
    
    subgraph "Module 1: Financial Health Scorer"
        M1_IN[X_financial: 22 features]
        M1_MODEL[XGBoost/LightGBM]
        M1_OUT[S‚ÇÅ: Financial Health Score]
    end
    
    subgraph "Module 2: Credit Behavior Scorer"
        M2_IN[X_credit: 13 features]
        M2_MODEL[XGBoost/Random Forest]
        M2_OUT[S‚ÇÇ: Credit Behavior Score]
    end
    
    subgraph "Module 3: Business Quality Scorer"
        M3_IN[X_business: 14 features]
        M3_MODEL[Random Forest/LightGBM]
        M3_OUT[S‚ÇÉ: Business Quality Score]
    end
    
    subgraph "Module 4: Stability & Risk Scorer"
        M4_IN[X_stability: 18 features]
        M4_MODEL[XGBoost/LightGBM]
        M4_OUT[S‚ÇÑ: Stability Risk Score]
    end
    
    subgraph "Meta-Model Layer"
        META_IN[Vector: S‚ÇÅ, S‚ÇÇ, S‚ÇÉ, S‚ÇÑ]
        META_MODEL[Logistic Regression / Light XGBoost]
        META_OUT[Final PD Score]
    end
    
    I1 --> M1_IN & M2_IN & M3_IN & M4_IN
    M1_IN --> M1_MODEL --> M1_OUT
    M2_IN --> M2_MODEL --> M2_OUT
    M3_IN --> M3_MODEL --> M3_OUT
    M4_IN --> M4_MODEL --> M4_OUT
    M1_OUT & M2_OUT & M3_OUT & M4_OUT --> META_IN
    META_IN --> META_MODEL --> META_OUT
    
    style M1_OUT fill:#90EE90
    style M2_OUT fill:#87CEEB
    style M3_OUT fill:#FFD700
    style M4_OUT fill:#FFA500
    style META_OUT fill:#FF6B6B
```

### 3.1. Module 1: Financial Health Scorer

**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° s·ª©c kh·ªèe t√†i ch√≠nh v√† kh·∫£ nƒÉng sinh l·ªùi c·ªßa doanh nghi·ªáp

**Input Features (22 features):**

#### T·ª´ B√°o c√°o t√†i ch√≠nh (12 features)

| Feature | C√¥ng th·ª©c | √ù nghƒ©a |
|---------|-----------|---------|
| `revenue_growth` | `(Doanh thu nƒÉm n - Doanh thu nƒÉm n-1) / Doanh thu nƒÉm n-1` | T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng |
| `profit_margin` | `L·ª£i nhu·∫≠n r√≤ng / Doanh thu` | Kh·∫£ nƒÉng sinh l·ªùi |
| `roa` | `L·ª£i nhu·∫≠n r√≤ng / T·ªïng t√†i s·∫£n` | Hi·ªáu qu·∫£ s·ª≠ d·ª•ng t√†i s·∫£n |
| `roe` | `L·ª£i nhu·∫≠n r√≤ng / V·ªën ch·ªß s·ªü h·ªØu` | Hi·ªáu su·∫•t v·ªën |
| `current_ratio` | `T√†i s·∫£n ng·∫Øn h·∫°n / N·ª£ ng·∫Øn h·∫°n` | Kh·∫£ nƒÉng thanh to√°n |
| `quick_ratio` | `(TSNH - H√†ng t·ªìn kho) / N·ª£ ng·∫Øn h·∫°n` | Thanh kho·∫£n nhanh |
| `debt_to_equity` | `T·ªïng n·ª£ / V·ªën ch·ªß s·ªü h·ªØu` | ƒê√≤n b·∫©y t√†i ch√≠nh |
| `debt_to_asset` | `T·ªïng n·ª£ / T·ªïng t√†i s·∫£n` | T·ª∑ l·ªá n·ª£ |
| `dscr` | `EBITDA / T·ªïng nghƒ©a v·ª• n·ª£ h√†ng nƒÉm` | Kh·∫£ nƒÉng tr·∫£ n·ª£ |
| `inventory_turnover` | `Gi√° v·ªën h√†ng b√°n / H√†ng t·ªìn kho TB` | Hi·ªáu qu·∫£ qu·∫£n l√Ω HTK |
| `receivable_turnover` | `Doanh thu / Kho·∫£n ph·∫£i thu TB` | Hi·ªáu qu·∫£ thu h·ªìi c√¥ng n·ª£ |
| `asset_turnover` | `Doanh thu / T·ªïng t√†i s·∫£n` | Hi·ªáu qu·∫£ s·ª≠ d·ª•ng TS |

#### T·ª´ D√≤ng ti·ªÅn (10 features)

| Feature | M√¥ t·∫£ | C√¥ng th·ª©c |
|---------|-------|-----------|
| `free_cash_flow` | D√≤ng ti·ªÅn t·ª± do | `OCF - CapEx` |
| `operating_cash_flow_ratio` | T·ª∑ l·ªá d√≤ng ti·ªÅn ho·∫°t ƒë·ªông | `OCF / Current Liabilities` |
| `cash_conversion_cycle` | Chu k·ª≥ chuy·ªÉn ƒë·ªïi ti·ªÅn | `DSO + DIO - DPO` |
| `days_sales_outstanding` | S·ªë ng√†y b√°n ch·ªãu (DSO) | `(Ph·∫£i thu / Doanh thu) √ó 360` |
| `days_payables_outstanding` | S·ªë ng√†y mua ch·ªãu (DPO) | `(Ph·∫£i tr·∫£ / COGS) √ó 360` |
| `avg_daily_balance` | S·ªë d∆∞ b√¨nh qu√¢n ng√†y (3 th√°ng) | `Œ£(S·ªë d∆∞ cu·ªëi ng√†y) / S·ªë ng√†y` |
| `min_balance_3m` | S·ªë d∆∞ th·∫•p nh·∫•t 3 th√°ng | `min(s·ªë d∆∞)` |
| `cash_flow_volatility` | ƒê·ªô bi·∫øn ƒë·ªông d√≤ng ti·ªÅn | `std(d√≤ng ti·ªÅn h√†ng ng√†y)` |
| `net_cash_flow` | D√≤ng ti·ªÅn r√≤ng TB/th√°ng | `avg_deposits - avg_withdrawals` |
| `overdraft_count` | S·ªë l·∫ßn th·∫•u chi | `count(balance < 0)` |

**Output:** `financial_health_score` (0-1)

---

### 3.2. Module 2: Credit Behavior Scorer

**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° l·ªãch s·ª≠ t√≠n d·ª•ng v√† h√†nh vi tr·∫£ n·ª£

**Input Features (13 features):**

#### T·ª´ CIC (Credit Information Center)

| Feature | M√¥ t·∫£ |
|---------|-------|
| `cic_score` | ƒêi·ªÉm CIC (n·∫øu c√≥) |
| `num_active_loans` | S·ªë kho·∫£n vay ƒëang c√≥ |
| `total_outstanding_debt` | T·ªïng d∆∞ n·ª£ hi·ªán t·∫°i |
| `max_past_due_days` | S·ªë ng√†y qu√° h·∫°n cao nh·∫•t (12 th√°ng) |
| `num_past_due_30d` | S·ªë l·∫ßn qu√° h·∫°n > 30 ng√†y (12 th√°ng) |
| `num_past_due_90d` | S·ªë l·∫ßn qu√° h·∫°n > 90 ng√†y (12 th√°ng) |
| `debt_burden_ratio` | `T·ªïng d∆∞ n·ª£ / Doanh thu th√°ng` |
| `credit_history_length` | S·ªë nƒÉm c√≥ quan h·ªá t√≠n d·ª•ng |
| `previous_default_history` | Binary: C√≥ l·ªãch s·ª≠ v·ª° n·ª£ (1=C√≥, 0=Kh√¥ng) |

#### T·ª´ Transaction Patterns

| Feature | M√¥ t·∫£ |
|---------|-------|
| `num_transactions_3m` | S·ªë giao d·ªãch 3 th√°ng |
| `avg_monthly_deposits` | Ti·ªÅn g·ª≠i TB/th√°ng |
| `avg_monthly_withdrawals` | Ti·ªÅn r√∫t TB/th√°ng |
| `transaction_regularity_score` | ƒêi·ªÉm ƒë·ªÅu ƒë·∫∑n giao d·ªãch (0-1) |

**Output:** `credit_behavior_score` (0-1)

---

### 3.3. Module 3: Business Quality Scorer

**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng doanh nghi·ªáp, nƒÉng l·ª±c ng∆∞·ªùi ƒëi·ªÅu h√†nh, v√† competitive advantage

**Input Features (14 features):**

#### NƒÉng l·ª±c Ng∆∞·ªùi ƒëi·ªÅu h√†nh

| Feature | M√¥ t·∫£ | Ki·ªÉu |
|---------|-------|------|
| `owner_age` | Tu·ªïi ch·ªß doanh nghi·ªáp | Numeric |
| `owner_education` | Tr√¨nh ƒë·ªô h·ªçc v·∫•n | Categorical (1-5) |
| `owner_experience` | S·ªë nƒÉm kinh nghi·ªám | Numeric |

#### Ch·∫•t l∆∞·ª£ng S·∫£n ph·∫©m & C·∫°nh tranh

| Feature | M√¥ t·∫£ | Ki·ªÉu |
|---------|-------|------|
| `product_differentiation_score` | M·ª©c ƒë·ªô kh√°c bi·ªát s·∫£n ph·∫©m | Numeric (1-10) |
| `industry_competition_intensity` | C∆∞·ªùng ƒë·ªô c·∫°nh tranh ng√†nh | Numeric (1-10) |

#### Quan h·ªá Kinh doanh

| Feature | M√¥ t·∫£ |
|---------|-------|
| `supplier_relationships` | S·ªë nh√† cung c·∫•p ch√≠nh |
| `customer_concentration` | T·ª∑ tr·ªçng KH l·ªõn nh·∫•t / Doanh thu |
| `digital_footprint` | M·ª©c ƒë·ªô hi·ªán di·ªán s·ªë (website, social) |

#### NƒÉng l·ª±c Ho·∫°t ƒë·ªông

| Feature | M√¥ t·∫£ | C√¥ng th·ª©c |
|---------|-------|-----------|
| `business_age` | S·ªë nƒÉm ho·∫°t ƒë·ªông | Numeric |
| `num_employees` | S·ªë l∆∞·ª£ng nh√¢n vi√™n | Numeric |
| `employee_productivity_score` | NƒÉng su·∫•t nh√¢n vi√™n | `Doanh thu / S·ªë nh√¢n vi√™n` |
| `revenue_capacity_ratio` | T·ª∑ l·ªá doanh thu/c√¥ng su·∫•t | `Doanh thu th·ª±c t·∫ø / Doanh thu l√Ω thuy·∫øt` |
| `financial_data_reliability_score` | ƒê·ªô tin c·∫≠y d·ªØ li·ªáu t√†i ch√≠nh | Numeric (0-1) |

**Output:** `business_quality_score` (0-1)

---

### 3.4. Module 4: Stability & Risk Scorer

**M·ª•c ƒë√≠ch:** ƒê√°nh gi√° t√≠nh ·ªïn ƒë·ªãnh v√† c√°c r·ªßi ro t·ª´ m√¥i tr∆∞·ªùng, l·ªãch s·ª≠, v√† t√†i s·∫£n ƒë·∫£m b·∫£o

**Input Features (18 features):**

#### L·ªãch s·ª≠ & ·ªîn ƒë·ªãnh

| Feature | M√¥ t·∫£ |
|---------|-------|
| `founding_year` | NƒÉm th√†nh l·∫≠p |
| `years_at_current_location` | S·ªë nƒÉm t·∫°i ƒë·ªãa ƒëi·ªÉm hi·ªán t·∫°i |
| `industry_changes_count` | S·ªë l·∫ßn ƒë·ªïi ng√†nh ngh·ªÅ |
| `past_bankruptcy` | Binary: L·ªãch s·ª≠ ph√° s·∫£n |
| `ownership_stability` | T·ª∑ l·ªá s·ªü h·ªØu ·ªïn ƒë·ªãnh (kh√¥ng ƒë·ªïi ch·ªß) |

#### R·ªßi ro Ng√†nh & V√πng (TP.HCM scope)

| Feature | M√¥ t·∫£ | Ki·ªÉu |
|---------|-------|------|
| `industry_code` | M√£ ng√†nh VSIC | Categorical |
| `industry_risk_score` | ƒêi·ªÉm r·ªßi ro ng√†nh ngh·ªÅ | Numeric (1-10, tra b·∫£ng) |
| `industry_lifecycle_stage` | Giai ƒëo·∫°n chu k·ª≥ | Categorical (Growth/Mature/Decline) |
| `district_code` | M√£ qu·∫≠n/huy·ªán TP.HCM | Categorical (24 qu·∫≠n) |
| `district_risk_score` | ƒêi·ªÉm r·ªßi ro theo qu·∫≠n | Numeric (1-10) |
| `business_zone` | Khu v·ª±c KD | Categorical (CBD/Suburban) |
| `district_business_density` | M·∫≠t ƒë·ªô DN trong qu·∫≠n | Numeric (DN/km¬≤) |
| `avg_income_district` | Thu nh·∫≠p b√¨nh qu√¢n qu·∫≠n | Numeric (VNƒê/th√°ng) |

#### T√†i s·∫£n ƒê·∫£m b·∫£o

| Feature | M√¥ t·∫£ | Ki·ªÉu |
|---------|-------|------|
| `has_collateral` | C√≥ TSƒêB hay kh√¥ng | Binary |
| `collateral_value` | Gi√° tr·ªã TSƒêB | Numeric |
| `loan_to_value` | `H·∫°n m·ª©c vay / Gi√° tr·ªã TSƒêB` | Numeric |
| `collateral_liquidity_score` | ƒêi·ªÉm thanh kho·∫£n TSƒêB | Numeric (1-10) |
| `collateral_type` | Lo·∫°i TSƒêB | Categorical (Real Estate/Equipment/Other) |

**Output:** `stability_risk_score` (0-1)

---

### 3.5. T·ªïng h·ª£p Features

| Module | S·ªë l∆∞·ª£ng Features | Ngu·ªìn g·ªëc ch·ªß y·∫øu |
|--------|-------------------|-------------------|
| **Module 1: Financial Health** | 22 | ƒê·ªãnh l∆∞·ª£ng (100%) |
| **Module 2: Credit Behavior** | 13 | ƒê·ªãnh l∆∞·ª£ng (100%) |
| **Module 3: Business Quality** | 14 | H·ªón h·ª£p (60% ƒë·ªãnh l∆∞·ª£ng, 40% ƒë·ªãnh t√≠nh s·ªë h√≥a) |
| **Module 4: Stability & Risk** | 18 | H·ªón h·ª£p (50% ƒë·ªãnh l∆∞·ª£ng, 50% ƒë·ªãnh t√≠nh s·ªë h√≥a) |
| **T·ªîNG C·ªòNG** | **67 features** | **~75% ƒë·ªãnh l∆∞·ª£ng, ~25% ƒë·ªãnh t√≠nh s·ªë h√≥a** |

---

## 4. Feature Engineering & Normalization

### 4.1. Bi·∫øn ƒë·ªïi d·ªØ li·ªáu

#### Log Transform (cho bi·∫øn l·ªách ph·∫£i)
√Åp d·ª•ng log transformation cho c√°c bi·∫øn c√≥ ph√¢n ph·ªëi l·ªách ph·∫£i nh∆∞ doanh thu, t·ªïng t√†i s·∫£n, v·ªën ƒëi·ªÅu l·ªá.

#### T·ª∑ l·ªá & T∆∞∆°ng t√°c
T·∫°o c√°c bi·∫øn t∆∞∆°ng t√°c gi·ªØa c√°c ch·ªâ s·ªë t√†i ch√≠nh ƒë·ªÉ n·∫Øm b·∫Øt m·ªëi quan h·ªá phi tuy·∫øn.

### 4.2. Chu·∫©n h√≥a (Normalization)

#### Min-Max Scaling (cho features c√≥ ph√¢n ph·ªëi ƒë·ªìng ƒë·ªÅu)
Scale c√°c features v·ªÅ kho·∫£ng [0, 1].

#### Standardization (cho features c√≥ ph√¢n ph·ªëi chu·∫©n)
```python
z = (x - Œº) / œÉ
```

Chu·∫©n h√≥a features theo ph√¢n ph·ªëi chu·∫©n v·ªõi mean = 0, std = 1.

### 4.3. X·ª≠ l√Ω Missing Values

- Median imputation cho numeric features
- Mode imputation cho categorical features
- Xem x√©t KNN imputation cho missing values c√≥ c·∫•u tr√∫c

---

## 5. Ki·∫øn tr√∫c M√¥ h√¨nh (Modular Model Architecture)

### 5.1. Tier 1: Specialized Scoring Modules

M·ªói module s·ª≠ d·ª•ng ensemble ri√™ng bi·ªát ƒë·ªÉ t·ªëi ∆∞u cho domain c·ª• th·ªÉ.

#### Module 1: Financial Health Scorer

**Model Stack:**
```python
# Base Models
model_1a = XGBoost(
    objective='reg:squarederror',
    max_depth=5,
    learning_rate=0.05,
    n_estimators=200,
    subsample=0.8
)

model_1b = LightGBM(
    objective='regression',
    num_leaves=31,
    learning_rate=0.05,
    n_estimators=200
)

# Ensemble
financial_health_score = 0.6 * model_1a.predict(X_financial) + 
                         0.4 * model_1b.predict(X_financial)
```

**Hyperparameters:**
- Focus on financial ratios and cash flow metrics
- L2 regularization to prevent overfitting on financial data
- Feature importance: ROA, DSCR, Current Ratio, Free Cash Flow

---

#### Module 2: Credit Behavior Scorer

**Model Stack:**
```python
# Base Models
model_2a = XGBoost(
    objective='reg:squarederror',
    scale_pos_weight=3,  # Higher weight for default history
    max_depth=4,
    learning_rate=0.05,
    n_estimators=150
)

model_2b = RandomForest(
    n_estimators=200,
    max_depth=8,
    min_samples_split=5,
    class_weight='balanced'
)

# Ensemble
credit_behavior_score = 0.7 * model_2a.predict(X_credit) + 
                        0.3 * model_2b.predict(X_credit)
```

**Hyperparameters:**
- Heavier penalty cho past due features
- Feature importance: num_past_due_90d, max_past_due_days, debt_burden_ratio

---

#### Module 3: Business Quality Scorer

**Model Stack:**
```python
# Base Models with Categorical Encoding
encoder = TargetEncoder(cols=['owner_education', 'industry_code'])
X_business_encoded = encoder.fit_transform(X_business, y)

model_3a = RandomForest(
    n_estimators=250,
    max_depth=6,
    min_samples_split=10
)

model_3b = LightGBM(
    objective='regression',
    num_leaves=25,
    learning_rate=0.03,
    categorical_feature=['owner_education', 'industry_code']
)

# Ensemble
business_quality_score = 0.5 * model_3a predict(X_business_encoded) +
                         0.5 * model_3b.predict(X_business_encoded)
```

**Hyperparameters:**
- Categorical encoding cho education, industry
- Feature importance: owner_experience, employee_productivity, business_age

---

#### Module 4: Stability & Risk Scorer

**Model Stack:**
```python
# Base Models
model_4a = XGBoost(
    objective='reg:squarederror',
    max_depth=5,
    learning_rate=0.05,
    n_estimators=200
)

model_4b = LightGBM(
    objective='regression',
    num_leaves=31,
    learning_rate=0.05
)

# Ensemble with Risk Adjustment
base_score = 0.6 * model_4a.predict(X_stability) + 
             0.4 * model_4b.predict(X_stability)

# Apply collateral adjustment
if has_collateral:
    stability_risk_score = base_score * (1 + 0.1 * collateral_liquidity_score/10)
else:
    stability_risk_score = base_score * 0.9  # Penalty for no collateral
```

**Hyperparameters:**
- Feature importance: district_risk_score, industry_risk_score, collateral_liquidity
- Explicit handling cho collateral features

---

### 5.2. Tier 2: Meta-Ensemble Model

**M·ª•c ƒë√≠ch:** K·∫øt h·ª£p 4 intermediate scores t·ª´ specialized modules th√†nh final PD score.

**Model Architecture:**

```python
# Input: 4 intermediate scores
X_meta = np.column_stack([
    financial_health_score,     # S‚ÇÅ
    credit_behavior_score,      # S‚ÇÇ
    business_quality_score,     # S‚ÇÉ
    stability_risk_score        # S‚ÇÑ
])

# Option 1: Weighted Logistic Regression (Recommended for Explainability)
meta_model = LogisticRegression(
    penalty='l2',
    C=1.0,
    class_weight='balanced',
    solver='lbfgs'
)

# Option 2: Light XGBoost (Better performance)
meta_model = XGBoost(
    objective='binary:logistic',
    max_depth=3,               # Shallow tree for interpretability
    learning_rate=0.1,
    n_estimators=50,
    subsample=0.8
)

# Train meta-model
meta_model.fit(X_meta, y_default)

# Final prediction
final_pd_score = meta_model.predict_proba(X_meta)[:, 1]
```

**∆Øu ƒëi·ªÉm Meta-Model:**
- ‚úÖ **Explainable**: C√≥ th·ªÉ ph√¢n t√≠ch contribution c·ªßa t·ª´ng module
- ‚úÖ **Robust**: N·∫øu 1 module thi·∫øu data, v·∫´n d√πng 3 modules c√≤n l·∫°i
- ‚úÖ **Flexible**: C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh weights theo business rules

**Weights Analysis Example:**
```python
# Logistic Regression Coefficients
print(meta_model.coef_)
# Output: [0.35, 0.40, 0.15, 0.10]
# ‚Üí Credit Behavior (40%) c√≥ impact cao nh·∫•t
# ‚Üí Financial Health (35%) l√† y·∫øu t·ªë th·ª© 2
# ‚Üí Business Quality (15%) v√† Stability (10%) l√† h·ªó tr·ª£
```

---

### 5.3. H√†m d·ª± ƒëo√°n cu·ªëi c√πng

**Full Pipeline:**

```python
def predict_credit_risk(borrower_data):
    """
    End-to-end prediction pipeline
    
    Input: borrower_data (dict with all raw features)
    Output: {
        pd_score: float,
        risk_grade: str,
        module_scores: dict,
        recommendation: str,
        credit_limit: float
    }
    """
    
    # Step 1: Feature Engineering & Extraction
    X_financial = extract_financial_features(borrower_data)
    X_credit = extract_credit_features(borrower_data)
    X_business = extract_business_features(borrower_data)
    X_stability = extract_stability_features(borrower_data)
    
    # Step 2: Normalize features
    X_financial_norm = scaler_financial.transform(X_financial)
    X_credit_norm = scaler_credit.transform(X_credit)
    X_business_norm = scaler_business.transform(X_business)
    X_stability_norm = scaler_stability.transform(X_stability)
    
    # Step 3: Module-level predictions
    S1 = module_1.predict(X_financial_norm)  # Financial Health
    S2 = module_2.predict(X_credit_norm)     # Credit Behavior  
    S3 = module_3.predict(X_business_norm)   # Business Quality
    S4 = module_4.predict(X_stability_norm)  # Stability & Risk
    
    # Step 4: Meta-model prediction
    X_meta = np.array([[S1, S2, S3, S4]])
    pd_score = meta_model.predict_proba(X_meta)[0, 1]
    
    # Step 5: Risk Grading
    if pd_score < 0.05:
        risk_grade = 'Low'
        recommendation = 'Auto-Approve'
    elif pd_score < 0.15:
        risk_grade = 'Medium'
        recommendation = 'Manual Review'
    else:
        risk_grade = 'High'
        recommendation = 'Auto-Reject'
    
    # Step 6: Credit Limit Calculation (for Low/Medium risk)
    if pd_score < 0.15:
        base_limit = borrower_data['monthly_revenue'] * 3
        risk_adjustment = (1 - pd_score * 2)  # Decrease with PD
        credit_limit = base_limit * risk_adjustment
    else:
        credit_limit = 0
    
    # Return comprehensive result
    return {
        'pd_score': pd_score,
        'risk_grade': risk_grade,
        'module_scores': {
            'financial_health': S1,
            'credit_behavior': S2,
            'business_quality': S3,
            'stability_risk': S4
        },
        'recommendation': recommendation,
        'credit_limit': credit_limit,
        'explanation': generate_explanation(S1, S2, S3, S4, pd_score)
    }
```

**Output Example:**
```json
{
  "pd_score": 0.08,
  "risk_grade": "Medium",
  "module_scores": {
    "financial_health": 0.75,
    "credit_behavior": 0.45,
    "business_quality": 0.68,
    "stability_risk": 0.62
  },
  "recommendation": "Manual Review",
  "credit_limit": 450000000,
  "explanation": "Medium risk. Credit Behavior Score (0.45) is below threshold due to 2 past due incidents (>30 days). Financial health is good (0.75). Recommend manual review before approval."
}
```

---

## 6. Ki·∫øn tr√∫c H·ªá th·ªëng

### 6.1. System Architecture

```mermaid
graph TB
    subgraph "Data Sources"
        A1[Customer Application API]
        A2[Internal Banking System]
        A3[CIC API]
        A4[External Data Providers]
    end
    
    subgraph "Data Layer"
        B1[Data Ingestion Service]
        B2[Data Validation]
        B3[Data Enrichment]
        B4[(Feature Store<br/>PostgreSQL)]
    end
    
    subgraph "Processing Layer"
        C1[Feature Engineering Service]
        C2[Feature Normalization]
        C3[Missing Value Handler]
    end
    
    subgraph "Model Layer"
        D1[XGBoost Service]
        D2[Random Forest Service]
        D3[LightGBM Service]
        D4[Ensemble Aggregator]
    end
    
    subgraph "Decision Layer"
        E1[Risk Grading Engine]
        E2[Credit Limit Calculator]
        E3[Auto-Decision Engine]
    end
    
    subgraph "Output Layer"
        F1[REST API]
        F2[Dashboard UI]
        F3[Monitoring & Logging]
    end
    
    A1 & A2 & A3 & A4 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4
    B4 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D1 & D2 & D3
    D1 & D2 & D3 --> D4
    D4 --> E1
    E1 --> E2
    E2 --> E3
    E3 --> F1 & F2
    F1 & F2 --> F3
    
    style D4 fill:#FFD700
    style E3 fill:#FFA500
    style F3 fill:#87CEEB
```

### 6.2. Technology Stack

| Component | Technology | L√Ω do |
|-----------|-----------|-------|
| **API Gateway** | FastAPI / Flask | High performance, async support |
| **Feature Store** | PostgreSQL + Redis | Persistence + Caching |
| **ML Framework** | Scikit-learn, XGBoost, LightGBM | Industry standard |
| **Model Serving** | MLflow / BentoML | Version control & deployment |
| **Message Queue** | RabbitMQ / Kafka | Async processing, scalability |
| **Monitoring** | Prometheus + Grafana | Real-time metrics |
| **Logging** | ELK Stack | Centralized logging |
| **Container** | Docker + Kubernetes | Orchestration & scaling |

---

## 7. Verification Plan

### 7.1. Automated Tests

#### Unit Tests (Per Module)
```bash
# Test Module 1: Financial Health
pytest tests/unit/test_financial_health_module.py

# Test Module 2: Credit Behavior
pytest tests/unit/test_credit_behavior_module.py

# Test Module 3: Business Quality
pytest tests/unit/test_business_quality_module.py

# Test Module 4: Stability & Risk
pytest tests/unit/test_stability_risk_module.py

# Test Meta-Model
pytest tests/unit/test_meta_model.py

# Test Feature Engineering
pytest tests/unit/test_feature_engineering.py
```

#### Integration Tests
```bash
# Test end-to-end pipeline
pytest tests/integration/test_modular_pipeline.py

# Test missing data handling
pytest tests/integration/test_missing_data_scenarios.py

# Test consistency between modules
pytest tests/integration/test_module_consistency.py
```

#### Performance Tests
```bash
# Load test: 1000 concurrent requests
locust -f tests/load/locustfile.py --host=http://localhost:8000

# Latency target: < 500ms per prediction
# Throughput target: 1000 predictions/second
```

---

### 7.2. Model Validation Metrics

#### Per-Module Metrics

**Module 1 & 2 & 3 & 4 (Regression task cho scores):**

| Metric | Target | M√¥ t·∫£ |
|--------|--------|-------|
| **R¬≤ Score** | > 0.65 | Ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch |
| **MAE** | < 0.15 | Mean Absolute Error |
| **Feature Importance Top-3** | - | Top 3 features quan tr·ªçng nh·∫•t |

**Module-level Validation:**
```python
# Validate each module independently
for module_name, module_model in modules.items():
    y_pred_module = module_model.predict(X_test_module)
    
    r2 = r2_score(y_test_module, y_pred_module)
    mae = mean_absolute_error(y_test_module, y_pred_module)
    
    print(f"{module_name}: R¬≤={r2:.3f}, MAE={mae:.3f}")
    assert r2 > 0.65, f"{module_name} R¬≤ too low"
    assert mae < 0.15, f"{module_name} MAE too high"
```

---

#### Meta-Model Metrics (Binary Classification)

| Metric | Target | M√¥ t·∫£ |
|--------|--------|-------|
| **AUC-ROC** | > 0.80 | Kh·∫£ nƒÉng ph√¢n bi·ªát default/non-default |
| **Precision** | > 0.75 | ƒê·ªô ch√≠nh x√°c khi d·ª± ƒëo√°n default |
| **Recall** | > 0.70 | T·ª∑ l·ªá ph√°t hi·ªán ƒë∆∞·ª£c default |
| **F1-Score** | > 0.72 | C√¢n b·∫±ng Precision & Recall |
| **KS Statistic** | > 0.40 | Kh·∫£ nƒÉng ph√¢n t√°ch ph√¢n ph·ªëi |
| **Brier Score** | < 0.15 | Calibration quality |

**Confusion Matrix Analysis:**
```
                  Predicted
                  0      1
Actual  0      TN     FP
        1      FN     TP

Target Thresholds:
- FPR (False Positive Rate): < 10%
- FNR (False Negative Rate): < 15%
```

**Module Contribution Analysis:**
```python
# Analyze meta-model coefficients  
if isinstance(meta_model, LogisticRegression):
    coefficients = meta_model.coef_[0]
    for i, coef in enumerate(coefficients):
        print(f"Module {i+1} weight: {coef:.3f}")
    
# SHAP values for explainability
import shap
explainer = shap.Explainer(meta_model, X_meta_train)
shap_values = explainer(X_meta_test)
shap.summary_plot(shap_values)
```

---

### 7.3. Business Metrics

| Metric | Target | Hi·ªán t·∫°i (Truy·ªÅn th·ªëng) |
|--------|--------|-------------------------|
| **Processing Time** | < 5 ph√∫t | 5-15 ng√†y |
| **Auto-approval Rate** | 30-40% | 0% |
| **Manual Review Rate** | 40-50% | 100% |
| **Throughput** | 10,000 applications/day | ~100 applications/day |
| **Bad Debt Rate** | < 3% | 5-7% |
| **Model Accuracy** | > 80% | - |

**Explainability Metrics:**
```python
# For each prediction, check if explanation is available
def test_explainability():
    result = predict_credit_risk(borrower_data)
    
    assert 'module_scores' in result
    assert 'explanation' in result
    assert len(result['explanation']) > 0
    
    # Check if explanation mentions weak module
    scores = result['module_scores']
    min_score_module = min(scores, key=scores.get)
    assert min_score_module in result['explanation'].lower()
```

---

### 7.4. Validation Strategy

#### Cross-Validation (Per Module)

```python
from sklearn.model_selection import StratifiedKFold

# 5-fold cross-validation for each module
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for module_name, (X, y) in module_datasets.items():
    cv_scores = []
    for train_idx, val_idx in kfold.split(X, y):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        module_model.fit(X_train, y_train)
        score = module_model.score(X_val, y_val)
        cv_scores.append(score)
    
    print(f"{module_name}: CV R¬≤ = {np.mean(cv_scores):.3f} ¬± {np.std(cv_scores):.3f}")
```

#### Temporal Validation

```python
# Train on older data, test on newer data
train_data = data[data['date'] < '2024-01-01']
test_data = data[data['date'] >= '2024-01-01']

# This mimics real-world deployment scenario
```

---

### 7.5. Monitoring Metrics (Post-Deployment)

| Metric | Alert Threshold | Action |
|--------|-----------------|--------|
| **Model Drift (PSI)** | > 0.15 | Retrain required |
| **Prediction Latency** | > 1s | Scale infrastructure |
| **Module Score Correlation** | Changes > 20% | Investigate data quality |
| **Auto-Approval Default Rate** | > 5% | Tighten approval threshold |
| **Manual Review Overturn Rate** | > 30% | Review manual process |

**Drift Detection:**
```python
from scipy.stats import ks_2samp

# Monitor feature distribution drift
for feature in features:
    stat, pvalue = ks_2samp(train_data[feature], prod_data[feature])
    if pvalue < 0.05:
        print(f"WARNING: Feature {feature} has drifted (p={pvalue:.4f})")
        alert_team()
```

---

## H∆∞·ªõng d·∫´n Tri·ªÉn khai (Implementation Guidance)

### B∆∞·ªõc 1: Chu·∫©n b·ªã D·ªØ li·ªáu (Data Preparation)

#### 1.1. Thu th·∫≠p d·ªØ li·ªáu TP.HCM
- D·ªØ li·ªáu DN SME t·ª´ S·ªü K·∫ø ho·∫°ch & ƒê·∫ßu t∆∞ TP.HCM
- B√°o c√°o t√†i ch√≠nh m·∫´u (n·∫øu c√≥ t·ª´ ng√¢n h√†ng)
- D·ªØ li·ªáu CIC (n·∫øu ƒë∆∞·ª£c c·∫•p ph√©p)
- D·ªØ li·ªáu kinh t·∫ø vƒ© m√¥ HCM (GDP, thu nh·∫≠p b√¨nh qu√¢n theo qu·∫≠n)

#### 1.2. T·∫°o Synthetic Data (n·∫øu thi·∫øu d·ªØ li·ªáu th·ª±c)
S·ª≠ d·ª•ng ph√¢n ph·ªëi th·ªëng k√™ (lognormal, binomial) ƒë·ªÉ t·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p ph√π h·ª£p v·ªõi ƒë·∫∑c ƒëi·ªÉm SME t·∫°i HCM.

**Chi·∫øn l∆∞·ª£c Synthetic Data cho Modular Architecture:**
```python
# Generate realistic synthetic data for each module
def generate_synthetic_sme_data(n_samples=5000):
    # Module 1: Financial Health
    financial_data = generate_financial_metrics(
        revenue_range=(1e9, 100e9),  # 1-100 t·ª∑ VNƒê
        default_rate=0.08
    )
    
    # Module 2: Credit Behavior
    credit_data = generate_credit_history(
        cic_availability=0.7,  # 70% c√≥ CIC
        default_rate=0.08
    )
    
    # Module 3: Business Quality
    business_data = generate_business_attributes(
        owner_age_range=(30, 65),
        education_distribution=[0.1, 0.25, 0.35, 0.2, 0.1]  # 5 levels
    )
    
    # Module 4: Stability & Risk
    stability_data = generate_stability_metrics(
        hcmc_districts=24,
        industry_distribution=get_hcmc_industry_dist()
    )
    
    return pd.concat([financial_data, credit_data, business_data, stability_data], axis=1)
```

---

### B∆∞·ªõc 2: X√¢y d·ª±ng Feature Engineering Pipeline (Modular)

**C·∫•u tr√∫c Pipeline cho t·ª´ng Module:**

```python
class ModularFeatureEngineer:
    def __init__(self):
        self.financial_engineer = FinancialHealthFeatureEngineer()
        self.credit_engineer = CreditBehaviorFeatureEngineer()
        self.business_engineer = BusinessQualityFeatureEngineer()
        self.stability_engineer = StabilityRiskFeatureEngineer()
    
    def transform(self, raw_data):
        # Extract features for each module
        X_financial = self.financial_engineer.transform(raw_data)  # 22 features
        X_credit = self.credit_engineer.transform(raw_data)        # 13 features
        X_business = self.business_engineer.transform(raw_data)    # 14 features
        X_stability = self.stability_engineer.transform(raw_data)  # 18 features
        
        return {
            'financial': X_financial,
            'credit': X_credit,
            'business': X_business,
            'stability': X_stability
        }
```

**V√≠ d·ª•: Financial Health Feature Engineer:**
```python
class FinancialHealthFeatureEngineer:
    def transform(self, raw_data):
        features = {}
        
        # T√≠nh c√°c ch·ªâ s·ªë t√†i ch√≠nh
        features['roa'] = raw_data['net_income'] / raw_data['total_assets']
        features['current_ratio'] = raw_data['current_assets'] / raw_data['current_liabilities']
        features['dscr'] = raw_data['ebitda'] / raw_data['annual_debt_service']
        
        # T√≠nh cash flow metrics
        features['free_cash_flow'] = raw_data['operating_cf'] - raw_data['capex']
        features['cash_conversion_cycle'] = (
            self.calc_dso(raw_data) + 
            self.calc_dio(raw_data) - 
            self.calc_dpo(raw_data)
        )
        
        # ... 17 features kh√°c
        
        return pd.DataFrame(features)
```

---

### B∆∞·ªõc 3: Training Models (Modular Approach)

**Quy tr√¨nh Training:**

#### Phase 3A: Train Module 1 - Financial Health

```python
# 1. Prepare data
X_financial = feature_engineer.financial_engineer.transform(raw_data)
y_financial_health = calculate_financial_health_target(raw_data, default_labels)

# 2. Split data
X_train, X_test, y_train, y_test = train_test_split(
    X_financial, y_financial_health, 
    test_size=0.2, stratify=default_labels
)

# 3. Train base models
model_1a = XGBoost(**params_xgb_financial)
model_1b = LightGBM(**params_lgbm_financial)

model_1a.fit(X_train, y_train)
model_1b.fit(X_train, y_train)

# 4. Ensemble
financial_scores_train = 0.6 * model_1a.predict(X_train) + 0.4 * model_1b.predict(X_train)
financial_scores_test = 0.6 * model_1a.predict(X_test) + 0.4 * model_1b.predict(X_test)

# 5. Validate
r2 = r2_score(y_test, financial_scores_test)
print(f"Module 1 R¬≤: {r2:.3f}")
assert r2 > 0.65
```

#### Phase 3B: Train Module 2, 3, 4 (T∆∞∆°ng t·ª±)

```python
# Parallel training cho c√°c modules
modules = {
    'financial': train_financial_module(X_financial, y_financial),
    'credit': train_credit_module(X_credit, y_credit),
    'business': train_business_module(X_business, y_business),
    'stability': train_stability_module(X_stability, y_stability)
}

# Save intermediate scores for meta-model training
S_train = np.column_stack([
    modules['financial'].predict(X_financial_train),
    modules['credit'].predict(X_credit_train),
    modules['business'].predict(X_business_train),
    modules['stability'].predict(X_stability_train)
])
```

#### Phase 3C: Train Meta-Model

```python
# 1. Prepare meta-features (4 intermediate scores)
X_meta_train = S_train  # Shape: (n_samples, 4)
y_meta_train = default_labels_train

# 2. Train meta-model
meta_model = LogisticRegression(
    penalty='l2',
    C=1.0,
    class_weight='balanced'
)
meta_model.fit(X_meta_train, y_meta_train)

# 3. Validate
y_pred_proba = meta_model.predict_proba(X_meta_test)[:, 1]
auc = roc_auc_score(y_meta_test, y_pred_proba)
print(f"Meta-Model AUC: {auc:.3f}")
assert auc > 0.80

# 4. Analyze module contributions
print("Module Weights:")
for i, name in enumerate(['Financial', 'Credit', 'Business', 'Stability']):
    print(f"  {name}: {meta_model.coef_[0][i]:.3f}")
```

**Hyperparameter Tuning Strategy:**

```python
from sklearn.model_selection import GridSearchCV

# Tune each module independently
param_grid_financial = {
    'max_depth': [4, 5, 6],
    'learning_rate': [0.03, 0.05, 0.1],
    'n_estimators': [150, 200, 250]
}

grid_search = GridSearchCV(
    XGBoost(), 
    param_grid_financial,
    cv=5,
    scoring='r2',
    n_jobs=-1
)
grid_search.fit(X_financial_train, y_financial_train)
best_params = grid_search.best_params_
```

---

### B∆∞·ªõc 4: Deployment (Modular API)

**FastAPI Implementation:**

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI(title="SME Credit Scoring API")

class BorrowerData(BaseModel):
    # Financial data
    total_revenue: float
    net_income: float
    total_assets: float
    # ... other fields
    
class PredictionResponse(BaseModel):
    pd_score: float
    risk_grade: str
    module_scores: dict
    recommendation: str
    credit_limit: float
    explanation: str

@app.post("/predict", response_model=PredictionResponse)
async def predict_credit_risk(borrower: BorrowerData):
    # 1. Feature extraction per module
    features = feature_engineer.transform(borrower.dict())
    
    # 2. Module predictions
    S1 = module_financial.predict([features['financial']])[0]
    S2 = module_credit.predict([features['credit']])[0]
    S3 = module_business.predict([features['business']])[0]
    S4 = module_stability.predict([features['stability']])[0]
    
    # 3. Meta-model prediction
    X_meta = np.array([[S1, S2, S3, S4]])
    pd_score = meta_model.predict_proba(X_meta)[0, 1]
    
    # 4. Risk grading & credit limit
    risk_grade, recommendation = grade_risk(pd_score)
    credit_limit = calculate_credit_limit(pd_score, borrower.total_revenue)
    explanation = generate_explanation(S1, S2, S3, S4, pd_score)
    
    return PredictionResponse(
        pd_score=pd_score,
        risk_grade=risk_grade,
        module_scores={
            'financial_health': S1,
            'credit_behavior': S2,
            'business_quality': S3,
            'stability_risk': S4
        },
        recommendation=recommendation,
        credit_limit=credit_limit,
        explanation=explanation
    )

@app.get("/health")
async def health_check():
    return {"status": "healthy", "modules": 4, "meta_model": "loaded"}
```

**Handling Missing Data:**

```python
def handle_missing_module_data(features_dict, module_name):
    """
    Robust handling when module data is missing
    """
    if features_dict[module_name] is None or has_too_many_missing(features_dict[module_name]):
        # Use conservative default score
        default_scores = {
            'financial': 0.5,   # Neutral
            'credit': 0.4,      # Slightly conservative (missing CIC is risky)
            'business': 0.6,    # Slightly optimistic  
            'stability': 0.5    # Neutral
        }
        return default_scores[module_name]
    else:
        return modules[module_name].predict([features_dict[module_name]])[0]
```

---

## Checklist Tri·ªÉn khai (Modular Architecture)

### Phase 1: Research & Design (2 tu·∫ßn)
- [ ] Nghi√™n c·ª©u th√™m v·ªÅ credit scoring cho SME v√† t√†i li·ªáu th·∫©m ƒë·ªãnh VN
- [ ] Thu th·∫≠p d·ªØ li·ªáu th·ª±c t·∫ø (n·∫øu c√≥) ho·∫∑c chu·∫©n b·ªã synthetic data
- [ ] Finalize feature list cho 4 modules (67 features total)
- [ ] Thi·∫øt k·∫ø database schema cho feature store
- [ ] X√°c ƒë·ªãnh service level targets cho t·ª´ng module

### Phase 2A: Module Development - Financial Health (1 tu·∫ßn)
- [ ] X√¢y d·ª±ng FinancialHealthFeatureEngineer (22 features)
- [ ] Generate synthetic financial data
- [ ] Train XGBoost + LightGBM ensemble
- [ ] Validate: R¬≤ > 0.65, MAE < 0.15
- [ ] Unit tests cho financial module

### Phase 2B: Module Development - Credit Behavior (1 tu·∫ßn)  
- [ ] X√¢y d·ª±ng CreditBehaviorFeatureEngineer (13 features)
- [ ] Generate synthetic CIC data
- [ ] Train XGBoost + Random Forest ensemble
- [ ] Validate: R¬≤ > 0.65, MAE < 0.15
- [ ] Unit tests cho credit module

### Phase 2C: Module Development - Business Quality (1 tu·∫ßn)
- [ ] X√¢y d·ª±ng BusinessQualityFeatureEngineer (14 features)
- [ ] Handle categorical encoding (education, industry)
- [ ] Train Random Forest + LightGBM ensemble
- [ ] Validate: R¬≤ > 0.65, MAE < 0.15
- [ ] Unit tests cho business module

### Phase 2D: Module Development - Stability & Risk (1 tu·∫ßn)
- [ ] X√¢y d·ª±ng StabilityRiskFeatureEngineer (18 features)
- [ ] T·∫°o b·∫£ng district risk scores cho TP.HCM
- [ ] Train XGBoost + LightGBM ensemble
- [ ] Validate: R¬≤ > 0.65, MAE < 0.15
- [ ] Unit tests cho stability module

### Phase 3: Meta-Model Development (1 tu·∫ßn)
- [ ] Collect intermediate scores t·ª´ 4 modules
- [ ] Train Logistic Regression meta-model
- [ ] Alternative: Train Light XGBoost meta-model
- [ ] Validate: AUC > 0.80, F1 > 0.72
- [ ] Analyze module contribution weights
- [ ] Implement SHAP explainability

### Phase 4: Integration & API (1 tu·∫ßn)
- [ ] Build modular prediction pipeline
- [ ] Implement FastAPI endpoints
- [ ] Add missing data handling logic
- [ ] Create explanation generation function
- [ ] Integration tests (test_modular_pipeline.py)
- [ ] Test missing data scenarios

### Phase 5: Testing & Validation (1 tu·∫ßn)
- [ ] Unit tests cho t·∫•t c·∫£ modules
- [ ] Integration tests end-to-end
- [ ] Load testing (1000 concurrent requests)
- [ ] Validate latency < 500ms per prediction
- [ ] Cross-validation cho t·ª´ng module
- [ ] Temporal validation (train on old, test on new data)

### Phase 6: Demo & Presentation (1 tu·∫ßn)  
- [ ] Chu·∫©n b·ªã demo v·ªõi d·ªØ li·ªáu m·∫´u TP.HCM
- [ ] T·∫°o dashboard visualize module scores
- [ ] Vi·∫øt b√°o c√°o k·ªπ thu·∫≠t v·ªÅ modular architecture
- [ ] Prepare explainability examples
- [ ] Present cho th·∫ßy/h·ªôi ƒë·ªìng

**T·ªïng th·ªùi gian: 8-9 tu·∫ßn**

---

## T√†i nguy√™n Tham kh·∫£o

### Datasets
- **Public SME Default Datasets**: Kaggle, UCI Machine Learning Repository
- **Vietnam SME Data**: T·ªïng c·ª•c Th·ªëng k√™, S·ªü KHƒêT TP.HCM
- **Industry Benchmarks**: State Bank of Vietnam reports

### Papers & Resources
- "Credit Scoring for SMEs using Machine Learning" (various papers)
- Basel II/III guidelines on credit risk
- Vietnam Central Bank regulations on SME lending

### Tools & Libraries
**Core**: pandas, numpy, scikit-learn
**ML**: xgboost, lightgbm, random forest
**API**: fastapi, uvicorn
**MLOps**: mlflow (experiment tracking), shap (interpretability)

---

## Note cu·ªëi c√πng

> [!IMPORTANT]
> Plan n√†y l√† **advisory/t∆∞ v·∫•n** v·ªõi **Modular Architecture**. B·∫°n s·∫Ω t·ª± tri·ªÉn khai t·ª´ng b∆∞·ªõc.
> 
> **Thay ƒë·ªïi quan tr·ªçng so v·ªõi plan ban ƒë·∫ßu:**
> 1. **Ki·∫øn tr√∫c Modular 2-t·∫ßng**: 4 scoring modules + 1 meta-model
> 2. **67 features** thay v√¨ ~50, ƒë∆∞·ª£c ph√¢n b·ªï khoa h·ªçc theo 4 domains
> 3. **T√≠ch h·ª£p th·ª±c ti·ªÖn VN**: D·ª±a tr√™n t√†i li·ªáu th·∫©m ƒë·ªãnh DN nh·ªè th·ª±c t·∫ø
> 4. **Explainability**: C√≥ th·ªÉ ph√¢n t√≠ch t·ª´ng module ri√™ng bi·ªát
> 5. **Robust**: X·ª≠ l√Ω t·ªët khi thi·∫øu d·ªØ li·ªáu
> 
> **C√°c ƒëi·ªÉm c·∫ßn l∆∞u √Ω khi th·ª±c hi·ªán:**
> 1. **Train t·ª´ng module ƒë·ªôc l·∫≠p** tr∆∞·ªõc, ƒë·∫£m b·∫£o R¬≤ > 0.65
> 2. **Validate t·ª´ng b∆∞·ªõc**, ƒë·ª´ng build to√†n b·ªô h·ªá th·ªëng m·ªôt l√∫c
> 3. **Focus v√†o feature quality** h∆°n l√† model complexity
> 4. **Document explainability** c·ªßa t·ª´ng module cho b√°o c√°o
> 5. **Test v·ªõi missing data scenarios** - ƒë√¢y l√† ƒëi·ªÉm m·∫°nh c·ªßa modular approach
> 6. **S·ª≠ d·ª•ng SHAP values** ƒë·ªÉ gi·∫£i th√≠ch meta-model decisions
> 
> **∆Øu ƒëi·ªÉm c·ªßa Modular Architecture:**
> - ‚úÖ D·ªÖ debug: Bi·∫øt ch√≠nh x√°c module n√†o c√≥ v·∫•n ƒë·ªÅ
> - ‚úÖ Incremental development: Train module 1, test, r·ªìi m·ªõi sang module 2
> - ‚úÖ Explainable AI: Gi·∫£i th√≠ch ƒë∆∞·ª£c t·∫°i sao reject/approve
> - ‚úÖ Production-ready: Robust v·ªõi data quality issues
> - ‚úÖ Scalable: D·ªÖ d√†ng th√™m module 5, 6 trong t∆∞∆°ng lai (VD: Social Media Module)
> 
> **Khi g·∫∑p v·∫•n ƒë·ªÅ, h√£y quay l·∫°i plan n√†y v√† review t·ª´ng b∆∞·ªõc.**

Ch√∫c b·∫°n tri·ªÉn khai th√†nh c√¥ng! üöÄ

---

## Ph·ª• l·ª•c: Module Dependencies & Data Flow

### Module Training Dependencies

```mermaid
graph LR
    A[Raw Data] --> B1[Module 1: Financial]
    A --> B2[Module 2: Credit]
    A --> B3[Module 3: Business]
    A --> B4[Module 4: Stability]
    
    B1 --> C[Intermediate Scores]
    B2 --> C
    B3 --> C
    B4 --> C
    
    C --> D[Meta-Model]
    D --> E[Final PD Score]
    
    style C fill:#FFD700
    style D fill:#FF6B6B
    style E fill:#90EE90
```

**No circular dependencies** ‚Üí C√≥ th·ªÉ train song song 4 modules, sau ƒë√≥ train meta-model.

### Recommended Training Order

1. **Parallel**: Module 1, 2, 3, 4 (c√≥ th·ªÉ train ƒë·ªìng th·ªùi)
2. **Sequential**: Meta-Model (c·∫ßn outputs t·ª´ 4 modules)

**Timeline estimate**: 
- Modules 1-4: 4 tu·∫ßn (1 tu·∫ßn/module, ho·∫∑c 2 tu·∫ßn n·∫øu parallel)
- Meta-model: 1 tu·∫ßn
- **Total core development**: 3-5 tu·∫ßn
