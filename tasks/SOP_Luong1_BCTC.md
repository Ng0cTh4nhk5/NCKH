# H∆∞·ªõng D·∫´n Chi Ti·∫øt: Lu·ªìng 1 - Thu Th·∫≠p BCTC T·ª´ C√¥ng Ty Ni√™m Y·∫øt

> **Th·ªùi gian**: 3 tu·∫ßn
> **Ng∆∞·ªùi th·ª±c hi·ªán**: Th√†nh vi√™n A
> **Output**: `synthetic_financial_10k.csv` + `distribution_params.json`

---

## üìã TU·∫¶N 1: DOWNLOAD BCTC

### B∆∞·ªõc 1.1: Nghi√™n C·ª©u Danh S√°ch C√¥ng Ty UPCOM (2 gi·ªù)

**M·ª•c ti√™u**: L·∫•y danh s√°ch 150-200 c√¥ng ty UPCOM ph√π h·ª£p v·ªõi ti√™u ch√≠ SME

#### C√¥ng vi·ªác c·ª• th·ªÉ:

1. **Truy c·∫≠p website HNX**
   - URL: https://www.hnx.vn/vi-vn/cong-ty-dai-chung.html
   - T√¨m m·ª•c "Danh s√°ch c√¥ng ty ƒë·∫°i ch√∫ng"
   - Download file Excel danh s√°ch c√¥ng ty UPCOM

2. **L·ªçc c√¥ng ty theo ti√™u ch√≠**
   
   M·ªü Excel, √°p d·ª•ng filter:
   ```
   Ti√™u ch√≠ l·ªçc:
   - Doanh thu nƒÉm g·∫ßn nh·∫•t < 200 t·ª∑ VNƒê
   - T·ªïng t√†i s·∫£n < 100 t·ª∑ VNƒê
   - Tr·ª• s·ªü t·∫°i TP.HCM (check c·ªôt "ƒê·ªãa ch·ªâ")
   - ƒêang ho·∫°t ƒë·ªông (status = "Active")
   ```

3. **T·∫°o file danh s√°ch cu·ªëi**
   
   T·∫°o file: `upcom_company_list.csv`
   
   C√°c c·ªôt c·∫ßn c√≥:
   ```csv
   ticker,company_name,address,revenue_2023,total_assets,employees,industry_code
   ABC,C√¥ng ty ABC,TP.HCM,150000000000,80000000000,120,46
   ```

4. **Ph√¢n nh√≥m c√¥ng ty**
   
   Chia th√†nh 4 batch, m·ªói batch ~50 c√¥ng ty:
   - `batch1_tickers.txt` - 50 c√¥ng ty ƒë·∫ßu
   - `batch2_tickers.txt` - 50 c√¥ng ty ti·∫øp
   - `batch3_tickers.txt` - 50 c√¥ng ty ti·∫øp
   - `batch4_tickers.txt` - 50 c√¥ng ty cu·ªëi

**Checkpoint**: File `upcom_company_list.csv` v·ªõi 150-200 d√≤ng

---

### B∆∞·ªõc 1.2: Setup M√¥i Tr∆∞·ªùng & Script Download (4 gi·ªù)

#### 1.2.1: C√†i ƒë·∫∑t Python Libraries

```bash
# T·∫°o virtual environment
conda create -n bctc_download python=3.10
conda activate bctc_download

# C√†i ƒë·∫∑t th∆∞ vi·ªán
pip install pandas openpyxl requests beautifulsoup4 selenium
pip install webdriver-manager  # T·ª± ƒë·ªông qu·∫£n l√Ω Chrome driver
```

#### 1.2.2: T·∫°o Script Download VietStock

**File**: `scripts/download_vietstock.py`

```python
"""
Script download BCTC t·ª´ VietStock
"""
import pandas as pd
import requests
import time
import os
from datetime import datetime

class VietStockDownloader:
    def __init__(self, output_dir='data/raw/bctc'):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        self.base_url = "https://finance.vietstock.vn"
        
    def download_company_bctc(self, ticker, years=[2020, 2021, 2022, 2023, 2024]):
        """
        Download BCTC cho 1 c√¥ng ty, nhi·ªÅu nƒÉm
        """
        print(f"Downloading {ticker}...")
        company_dir = f"{self.output_dir}/{ticker}"
        os.makedirs(company_dir, exist_ok=True)
        
        for year in years:
            try:
                # URL format VietStock
                url = f"{self.base_url}/{ticker}/tai-chinh/bao-cao-tai-chinh/?year={year}"
                
                # G·ª≠i request
                response = requests.get(url, timeout=30)
                
                if response.status_code == 200:
                    # L∆∞u file
                    filename = f"{company_dir}/{ticker}_{year}.html"
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(response.text)
                    print(f"  ‚úì {ticker} {year}")
                else:
                    print(f"  ‚úó {ticker} {year} - Failed")
                
                # Delay ƒë·ªÉ tr√°nh b·ªã ban
                time.sleep(2)
                
            except Exception as e:
                print(f"  ‚úó {ticker} {year} - Error: {e}")
                
    def download_batch(self, ticker_file):
        """
        Download batch t·ª´ file ticker list
        """
        with open(ticker_file, 'r') as f:
            tickers = [line.strip() for line in f if line.strip()]
        
        for ticker in tickers:
            self.download_company_bctc(ticker)
            time.sleep(3)  # Delay gi·ªØa c√°c c√¥ng ty

# S·ª≠ d·ª•ng
if __name__ == "__main__":
    downloader = VietStockDownloader(output_dir='data/raw/bctc/batch1')
    downloader.download_batch('batch1_tickers.txt')
```

#### 1.2.3: Script Alternative - CafeF

**File**: `scripts/download_cafef.py`

```python
"""
Backup script download t·ª´ CafeF n·∫øu VietStock fail
"""
import requests
import json

def download_cafef(ticker, year):
    """
    Download t·ª´ CafeF API
    """
    url = f"https://s.cafef.vn/Ajax/CongTy/BaoCaoTaiChinh.aspx"
    params = {
        'symbol': ticker,
        'year': year,
        'type': 1  # 1: BCTC nƒÉm, 2: BCTC qu√Ω
    }
    
    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        # X·ª≠ l√Ω v√† l∆∞u data
        return data
    return None
```

---

### B∆∞·ªõc 1.3: Download BCTC (3-4 ng√†y)

#### Chi·∫øn l∆∞·ª£c song song:

**N·∫øu 1 ng∆∞·ªùi**:
- Ch·∫°y tu·∫ßn t·ª± 4 batch, m·ªói batch ~1 ng√†y
- S√°ng: Setup + ch·∫°y batch
- Chi·ªÅu: Monitoring + x·ª≠ l√Ω l·ªói

**N·∫øu 4 ng∆∞·ªùi**:
- M·ªói ng∆∞·ªùi ch·∫°y 1 batch song song
- Ho√†n th√†nh trong 1 ng√†y

#### Checklist th·ª±c hi·ªán:

**Batch 1** (50 c√¥ng ty)
```bash
# Terminal 1
python scripts/download_vietstock.py --batch batch1_tickers.txt --output data/raw/bctc/batch1
```

- [ ] Ch·∫°y script
- [ ] Monitor progress (check log file)
- [ ] Ki·ªÉm tra s·ªë file downloaded: 50 c√¥ng ty √ó 5 nƒÉm = 250 files
- [ ] Ghi log c√°c ticker failed v√†o `batch1_failed.txt`
- [ ] Retry failed tickers (n·∫øu c√≥)

**Batch 2** (50 c√¥ng ty)
```bash
# Terminal 2 (song song)
python scripts/download_vietstock.py --batch batch2_tickers.txt --output data/raw/bctc/batch2
```

- [ ] T∆∞∆°ng t·ª± batch 1

**Batch 3 & 4**: T∆∞∆°ng t·ª±

#### X·ª≠ l√Ω l·ªói th∆∞·ªùng g·∫∑p:

| L·ªói | Nguy√™n nh√¢n | Gi·∫£i ph√°p |
|------|-------------|-----------|
| HTTP 429 | Rate limiting | TƒÉng delay l√™n 5s, retry sau 1 gi·ªù |
| HTTP 404 | Ticker kh√¥ng t·ªìn t·∫°i | B·ªè qua, ghi log |
| Timeout | M·∫°ng ch·∫≠m | TƒÉng timeout l√™n 60s, retry |
| Empty response | C√¥ng ty ch∆∞a c√≥ BCTC nƒÉm ƒë√≥ | B·ªè qua, ghi log |

**Checkpoint Tu·∫ßn 1**:
```
data/raw/bctc/
‚îú‚îÄ‚îÄ batch1/
‚îÇ   ‚îú‚îÄ‚îÄ ABC/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ABC_2020.html
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ABC_2021.html
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ XYZ/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ batch2/
‚îú‚îÄ‚îÄ batch3/
‚îî‚îÄ‚îÄ batch4/

Total: ~800-1000 files (200 c√¥ng ty √ó 5 nƒÉm, ch·∫•p nh·∫≠n 80% completeness)
```

---

## üìã TU·∫¶N 2: EXTRACT FEATURES

### B∆∞·ªõc 2.1: X√¢y D·ª±ng Parser (1 ng√†y)

#### 2.1.1: Ph√¢n t√≠ch c·∫•u tr√∫c HTML VietStock

**M·ªü 1 file m·∫´u**: `data/raw/bctc/batch1/ABC/ABC_2023.html`

Quan s√°t c·∫•u tr√∫c:
```html
<table class="table-balance-sheet">
  <tr>
    <td>T·ªïng t√†i s·∫£n</td>
    <td class="text-right">1,234,567</td>
  </tr>
  <tr>
    <td>N·ª£ ph·∫£i tr·∫£</td>
    <td class="text-right">567,890</td>
  </tr>
</table>
```

#### 2.1.2: Vi·∫øt Parser

**File**: `scripts/parse_bctc.py`

```python
"""
Parser BCTC t·ª´ HTML
"""
from bs4 import BeautifulSoup
import pandas as pd
import re

class BCTCParser:
    def __init__(self):
        self.field_mapping = {
            'T·ªïng t√†i s·∫£n': 'total_assets',
            'T√†i s·∫£n ng·∫Øn h·∫°n': 'current_assets',
            'N·ª£ ph·∫£i tr·∫£': 'total_liabilities',
            'N·ª£ ng·∫Øn h·∫°n': 'current_liabilities',
            'V·ªën ch·ªß s·ªü h·ªØu': 'equity',
            'Doanh thu': 'revenue',
            'L·ª£i nhu·∫≠n sau thu·∫ø': 'net_profit',
            'Gi√° v·ªën h√†ng b√°n': 'cogs',
            'H√†ng t·ªìn kho': 'inventory',
            'Kho·∫£n ph·∫£i thu': 'receivables'
        }
        
    def clean_number(self, text):
        """
        Chuy·ªÉn '1,234,567' -> 1234567
        """
        if not text:
            return None
        # X√≥a d·∫•u ph·∫©y, ƒë∆°n v·ªã
        clean = re.sub(r'[,\s]', '', text)
        try:
            return float(clean)
        except:
            return None
    
    def parse_html(self, html_file):
        """
        Parse 1 file HTML
        """
        with open(html_file, 'r', encoding='utf-8') as f:
            soup = BeautifulSoup(f.read(), 'html.parser')
        
        data = {}
        
        # T√¨m table balance sheet
        table = soup.find('table', class_='table-balance-sheet')
        if table:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 2:
                    label = cells[0].text.strip()
                    value = cells[1].text.strip()
                    
                    if label in self.field_mapping:
                        field_name = self.field_mapping[label]
                        data[field_name] = self.clean_number(value)
        
        return data
    
    def parse_company(self, ticker, company_dir):
        """
        Parse t·∫•t c·∫£ nƒÉm c·ªßa 1 c√¥ng ty
        """
        results = []
        
        for year in [2020, 2021, 2022, 2023, 2024]:
            file_path = f"{company_dir}/{ticker}_{year}.html"
            
            if os.path.exists(file_path):
                data = self.parse_html(file_path)
                data['ticker'] = ticker
                data['year'] = year
                results.append(data)
        
        return pd.DataFrame(results)

# Test
parser = BCTCParser()
df = parser.parse_company('ABC', 'data/raw/bctc/batch1/ABC')
print(df)
```

#### 2.1.3: Test Parser

```bash
# Ch·∫°y test v·ªõi 5 c√¥ng ty m·∫´u
python scripts/test_parser.py
```

**Expected output**:
```
   ticker  year  total_assets  revenue  net_profit  ...
0  ABC    2020  1000000000   500000000  50000000
1  ABC    2021  1200000000   600000000  60000000
...
```

---

### B∆∞·ªõc 2.2: Extract T·∫•t C·∫£ Companies (2-3 ng√†y)

**File**: `scripts/extract_all.py`

```python
"""
Extract t·∫•t c·∫£ BCTC th√†nh 1 file CSV
"""
import os
from parse_bctc import BCTCParser
import pandas as pd

def extract_batch(batch_dir, output_file):
    parser = BCTCParser()
    all_data = []
    
    # List t·∫•t c·∫£ ticker trong batch
    tickers = [d for d in os.listdir(batch_dir) if os.path.isdir(f"{batch_dir}/{d}")]
    
    for ticker in tickers:
        print(f"Processing {ticker}...")
        company_dir = f"{batch_dir}/{ticker}"
        df = parser.parse_company(ticker, company_dir)
        all_data.append(df)
    
    # Combine all
    result = pd.concat(all_data, ignore_index=True)
    
    # Save
    result.to_csv(output_file, index=False)
    print(f"Saved to {output_file}")
    
    return result

# Run cho t·∫•t c·∫£ batches
for i in range(1, 5):
    extract_batch(
        f"data/raw/bctc/batch{i}",
        f"data/processed/batch{i}_raw.csv"
    )
```

**Ch·∫°y**:
```bash
python scripts/extract_all.py
```

**Checkpoint**: 4 files CSV v·ªõi raw data

---

### B∆∞·ªõc 2.3: T√≠nh 12 Ch·ªâ S·ªë T√†i Ch√≠nh (1 ng√†y)

**File**: `scripts/calculate_ratios.py`

```python
"""
T√≠nh 12 financial ratios
"""
import pandas as pd
import numpy as np

def calculate_financial_ratios(df):
    """
    Input: DataFrame v·ªõi raw fields
    Output: DataFrame v·ªõi 12 ratios
    """
    result = df.copy()
    
    # 1. ROA (Return on Assets)
    result['roa'] = result['net_profit'] / result['total_assets']
    
    # 2. ROE (Return on Equity)  
    result['roe'] = result['net_profit'] / result['equity']
    
    # 3. Profit Margin
    result['profit_margin'] = result['net_profit'] / result['revenue']
    
    # 4. Revenue Growth (so v·ªõi nƒÉm tr∆∞·ªõc)
    result = result.sort_values(['ticker', 'year'])
    result['revenue_prev'] = result.groupby('ticker')['revenue'].shift(1)
    result['revenue_growth'] = (result['revenue'] - result['revenue_prev']) / result['revenue_prev']
    
    # 5. Current Ratio
    result['current_ratio'] = result['current_assets'] / result['current_liabilities']
    
    # 6. Quick Ratio
    result['quick_ratio'] = (result['current_assets'] - result['inventory']) / result['current_liabilities']
    
    # 7. Debt to Equity
    result['debt_to_equity'] = result['total_liabilities'] / result['equity']
    
    # 8. Debt to Assets
    result['debt_to_asset'] = result['total_liabilities'] / result['total_assets']
    
    # 9-12: Turnover ratios
    result['asset_turnover'] = result['revenue'] / result['total_assets']
    result['inventory_turnover'] = result['cogs'] / result['inventory']
    result['receivable_turnover'] = result['revenue'] / result['receivables']
    
    # DSCR c·∫ßn EBITDA - t·∫°m b·ªè qua ho·∫∑c estimate
    result['dscr'] = np.nan  # S·∫Ω estimate sau
    
    return result

# Apply
for i in range(1, 5):
    df = pd.read_csv(f"data/processed/batch{i}_raw.csv")
    df_ratios = calculate_financial_ratios(df)
    df_ratios.to_csv(f"data/processed/batch{i}_ratios.csv", index=False)
```

**Output**: `financial_features_real.csv` v·ªõi 12 features

---

## üìã TU·∫¶N 3: ANALYZE & GENERATE SYNTHETIC

### B∆∞·ªõc 3.1: EDA (1 ng√†y)

**File**: `notebooks/eda_financial.ipynb`

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load t·∫•t c·∫£ data
dfs = []
for i in range(1, 5):
    df = pd.read_csv(f"../data/processed/batch{i}_ratios.csv")
    dfs.append(df)

df_all = pd.concat(dfs, ignore_index=True)

# EDA
df_all.describe()

# Visualize distributions
features = ['roa', 'roe', 'current_ratio', 'debt_to_equity']
for feat in features:
    plt.figure()
    df_all[feat].dropna().hist(bins=50)
    plt.title(f'Distribution of {feat}')
    plt.savefig(f'plots/{feat}_dist.png')
```

**Checklist**:
- [ ] Ki·ªÉm tra missing values (< 20% cho m·ªói feature)
- [ ] Ph√°t hi·ªán outliers (IQR method)
- [ ] X√≥a outliers c·ª±c ƒëoan (> 5 std)
- [ ] Save cleaned data: `financial_features_clean.csv`

---

### B∆∞·ªõc 3.2: Fit Distributions (1 ng√†y)

```python
from scipy import stats

def fit_distribution(data, feature_name):
    """
    Fit best distribution
    """
    data_clean = data.dropna()
    
    # Test normality
    _, p_value = stats.normaltest(data_clean)
    
    if p_value > 0.05:
        # Normal
        params = stats.norm.fit(data_clean)
        return {'dist': 'normal', 'params': params}
    else:
        # Try lognormal
        params = stats.lognorm.fit(data_clean)
        return {'dist': 'lognorm', 'params': params}

# Fit all features
params_dict = {}
for feat in ['roa', 'roe', 'current_ratio', ...]:
    params_dict[feat] = fit_distribution(df_all[feat], feat)

# Save
import json
with open('data/distribution_params.json', 'w') as f:
    json.dump(params_dict, f, indent=2)
```

---

### B∆∞·ªõc 3.3: Generate Synthetic 10k (1 ng√†y)

```python
import json
import numpy as np
import pandas as pd

# Load params
with open('data/distribution_params.json', 'r') as f:
    params = json.load(f)

# Generate
n_samples = 10000
synthetic = {}

for feat, dist_info in params.items():
    if dist_info['dist'] == 'normal':
        mean, std = dist_info['params']
        synthetic[feat] = np.random.normal(mean, std, n_samples)
    elif dist_info['dist'] == 'lognorm':
        s, loc, scale = dist_info['params']
        synthetic[feat] = stats.lognorm.rvs(s, loc, scale, size=n_samples)

df_synthetic = pd.DataFrame(synthetic)

# Maintain correlations
from sklearn.covariance import LedoitWolf
cov = LedoitWolf().fit(df_all[features].dropna()).covariance_

# Adjust ƒë·ªÉ c√≥ correlation
# (S·ª≠ d·ª•ng Cholesky decomposition)

# Save
df_synthetic.to_csv('data/final/synthetic_financial_10k.csv', index=False)
```

---

## ‚úÖ CHECKLIST HO√ÄN TH√ÄNH

- [ ] Tu·∫ßn 1: 800-1000 file BCTC downloaded
- [ ] Tu·∫ßn 2: `financial_features_real.csv` v·ªõi 12 features
- [ ] Tu·∫ßn 3: `synthetic_financial_10k.csv` + `distribution_params.json`
- [ ] QA: Ki·ªÉm tra ph√¢n ph·ªëi h·ª£p l√Ω
- [ ] Documentation: Ghi log c√°c l·ªói, missing data

---

## üÜò TROUBLESHOOTING

**Q: VietStock block IP?**
A: Chuy·ªÉn sang CafeF ho·∫∑c s·ª≠ d·ª•ng proxy/VPN

**Q: Parser kh√¥ng ho·∫°t ƒë·ªông?**
A: Ki·ªÉm tra l·∫°i c·∫•u tr√∫c HTML, VietStock c√≥ th·ªÉ ƒë√£ thay ƒë·ªïi format

**Q: Missing data qu√° nhi·ªÅu?**
A: Ch·∫•p nh·∫≠n 70-80% completeness, interpolate ho·∫∑c b·ªè qua c√¥ng ty ƒë√≥
